{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Capítulo 10 - Processamento de Linguagem Natural</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****** Este Jupyter Notebook foi atualizado para a versão 3.6.1. da Linguagem Python em 05/07/2017 ******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similaridade de Texto\n",
    "\n",
    "Como computar a similaridade entre duas strings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 'Refrigerador Brastemp CFR45 20L frostfree'\n",
    "b = 'Geladeira Brastemp CFR45 20L com desgelo automático'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20L', 'Brastemp', 'CFR45'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokens similares\n",
    "tokensA = a.split()\n",
    "tokensB = b.split()\n",
    "set(tokensA).intersection(tokensB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 tokens similares de 9 tokens: 33.33% de similaridade\n"
     ]
    }
   ],
   "source": [
    "similar = len(set(tokensA).intersection(tokensB))\n",
    "total = len(set(tokensA).union(tokensB))\n",
    "print ('{} tokens similares de {} tokens: {:0.2f}% de similaridade'.format(similar, total, similar/total*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jellyfish in /Users/dmpm/anaconda/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /Users/dmpm/anaconda/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: metaphone in /Users/dmpm/anaconda/lib/python3.6/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install metaphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outras métricas usadas para similaridade de texto\n",
    "import jellyfish\n",
    "import fuzzywuzzy\n",
    "import metaphone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KS', '')\n",
      "('KS', '')\n"
     ]
    }
   ],
   "source": [
    "print (metaphone.doublemetaphone('caza'))\n",
    "print (metaphone.doublemetaphone('casa'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6568129284234019"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A \"jaro-distance\" é uma métrica para comparar strings curtas, como nomes de pessoas\n",
    "jellyfish.jaro_distance(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras Possibilidades\n",
    "\n",
    "* Extrair recursos nomeados para medir a importância de cada token\n",
    "* Usar algum texto básico para preprocessing (lowecase, stemming, etc)\n",
    "* Remover palavra-chave\n",
    "* Peso das palavras usando uma medida de importância (TF / IDF, por exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando word2vec Para Computar Similaridades entre Vetores\n",
    "https://radimrehurek.com/gensim/models/word2vec.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec é um grupo de modelos relacionados que são usados para produzir word embeddings. Esses modelos são redes neurais artificiais de duas camadas que são treinadas para reconstruir contextos linguísticos de palavras. O Word2vec toma como entrada um grande corpus de texto e produz um espaço vetorial, tipicamente de várias centenas de dimensões, com cada palavra única no corpus sendo atribuída um vetor correspondente no espaço. Os vetores de palavras são posicionados no espaço vetorial de tal forma que as palavras que compartilham contextos comuns no corpus estão localizadas próximas umas das outras no espaço."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Word2vec foi criado por uma equipe de pesquisadores liderada por Tomas Mikolov no Google. O algoritmo foi posteriormente analisado e explicado por outros pesquisadores. Incorporar vetores criados usando o algoritmo Word2vec tem muitas vantagens em comparação com algoritmos anteriores como Latent Semantic Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Leitura do Corpus\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o conteúdo do Corpus para um objeto Python\n",
    "with codecs.open('corpus.txt', encoding = 'utf8') as fp:\n",
    "    corpus = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokenization com NLTK - este processo é demorado!!!\n",
    "sentences = [[w.lower() for w in word_tokenize(sentence, language = 'portuguese')] for sentence in sent_tokenize(corpus, language = 'portuguese')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Treinando o modelo\n",
    "modelo = Word2Vec(sentences, size = 100, window = 5, min_count = 5, workers = 8)\n",
    "modelo.init_sims(replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('brastemp', 0.5971542000770569),\n",
       " ('torneira', 0.5934094190597534),\n",
       " ('cozinha', 0.5842926502227783),\n",
       " ('facilite', 0.5711125135421753),\n",
       " ('frost', 0.55544114112854),\n",
       " ('bebida', 0.5471072793006897),\n",
       " ('cerveja', 0.5417832136154175),\n",
       " ('inverse', 0.5413452386856079),\n",
       " ('cafeteira', 0.5392649173736572),\n",
       " ('estação', 0.5364927053451538)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.most_similar('geladeira')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensA = [t.lower() for t in tokensA]\n",
    "vectorsA = sum([modelo[token] for token in tokensA if token in modelo.raw_vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokensB = [t.lower() for t in tokensB]\n",
    "vectorsB = sum([modelo[token] for token in tokensB if token in modelo.raw_vocab])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similaridade: nan\n"
     ]
    }
   ],
   "source": [
    "from nltk.cluster.util import cosine_distance\n",
    "print ('Similaridade: {}'.format(abs(1 - cosine_distance(vectorsA, vectorsB))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=http://facebook.com/dsacademy>facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
